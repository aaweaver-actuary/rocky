{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is a CNN for learning whether a loss triangle is incremental or cumulative\n",
    "\n",
    "### 1. Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import torch\n",
    "\n",
    "# torch.nn is the neural network library - provides all the building blocks for neural networks\n",
    "# such as layers, loss functions, activation functions, etc.\n",
    "import torch.nn as nn\n",
    "\n",
    "# torch.optim is the optimization library - provides all the optimization algorithms\n",
    "# such as SGD, RMSProp, Adam, etc.\n",
    "import torch.optim as optim\n",
    "\n",
    "# torch.utils.data is the data loading and processing library - provides all the tools\n",
    "# to efficiently load and preprocess data\n",
    "# DataLoader is a tool to efficiently load data in batches\n",
    "# TensorDataset is a tool to efficiently load data in batches\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. define the CNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model inherits from nn.Module\n",
    "class SimpleCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple CNN model for triangle classification\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    num_classes: int\n",
    "        Number of classes in the dataset (2 for binary classification)\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    forward(x):\n",
    "        Forward pass of the model\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_classes : int = None\n",
    "        ):\n",
    "        \n",
    "        # call the __init__ method of the parent class nn.Module\n",
    "        super(SimpleCNN, self).__init__()\n",
    "\n",
    "        # define the layers of the model\n",
    "        \n",
    "        # conv1: 1 input channel, 8 output channels, kernel size 2, stride 1\n",
    "        # an input channel is a feature map (e.g. a grayscale image has 1 channel)\n",
    "        # an output channel is a feature map (e.g. a grayscale image has 1 channel)\n",
    "        # a kernel is a filter that is applied to the input image to extract features\n",
    "        # a stride is the number of pixels the kernel moves each time it is applied \n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=2, stride=1)\n",
    "        \n",
    "        # relu activation function = max(0, x)\n",
    "        # this is used to introduce non-linearity into the model\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # fc is a fully connected layer, meaning that each node in the layer is\n",
    "        # connected to every node in the previous layer\n",
    "        # 8 is the number of nodes in the previous layer\n",
    "        # num_classes is the number of nodes in the current layer, which is the number of classes\n",
    "        # in the dataset\n",
    "        self.fc = nn.Linear(8, num_classes)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x : torch.Tensor\n",
    "        ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the model. This method is called automatically when the model is called.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        x: torch.Tensor\n",
    "            Input tensor\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        x: torch.Tensor\n",
    "            Output tensor\n",
    "        \"\"\"\n",
    "        # apply the convolutional layer\n",
    "        x = self.conv1(x)\n",
    "\n",
    "        # apply the activation function\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # flatten the tensor so that it can be passed to the fully connected layer\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # apply the fully connected layer\n",
    "        x = self.fc(x)\n",
    "\n",
    "        # return the output tensor\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Sparkline Group extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The origin column names could not be set automatically.\n",
      "                  Please provide the origin column names manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Sparkline Group extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The origin column names could not be set automatically.\n",
      "                  Please provide the origin column names manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Sparkline Group extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The origin column names could not be set automatically.\n",
      "                  Please provide the origin column names manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Sparkline Group extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The origin column names could not be set automatically.\n",
      "                  Please provide the origin column names manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Sparkline Group extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The origin column names could not be set automatically.\n",
      "                  Please provide the origin column names manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Sparkline Group extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The origin column names could not be set automatically.\n",
      "                  Please provide the origin column names manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Sparkline Group extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The origin column names could not be set automatically.\n",
      "                  Please provide the origin column names manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Sparkline Group extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The origin column names could not be set automatically.\n",
      "                  Please provide the origin column names manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Sparkline Group extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The origin column names could not be set automatically.\n",
      "                  Please provide the origin column names manually.\n",
      "The origin column names could not be set automatically.\n",
      "                  Please provide the origin column names manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "c:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Sparkline Group extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "%run ../triangle.py\n",
    "\n",
    "file = r\"C:\\Users\\AndyW\\OneDrive\\work\\2022Q4 - OL Occ.xlsx\"\n",
    "\n",
    "ids = ['Reported Loss', 'Paid Loss', 'Paid DCCE', 'Reported Count', 'Closed Count']\n",
    "sheets = ['Reported Loss Development', 'Paid Loss Development', \"Paid DCCE Development\", \"Reported Count Development\", \"Closed Count Development\"]\n",
    "sht_dict = dict(zip(ids, sheets))\n",
    "cum_triangle_rng = \"B5:CD25\"\n",
    "inc_triangle_rng = \"B83:CD103\"\n",
    "\n",
    "cum_rpt_loss = Triangle.from_excel(file, 'Reported Loss', 1, sht_dict['Reported Loss'], cum_triangle_rng)\n",
    "cum_paid_loss = Triangle.from_excel(file, 'Paid Loss', 1, sht_dict['Paid Loss'], cum_triangle_rng)\n",
    "cum_paid_dcce = Triangle.from_excel(file, 'Paid DCCE', 1, sht_dict['Paid DCCE'], cum_triangle_rng)\n",
    "cum_rpt_count = Triangle.from_excel(file, 'Reported Count', 1, sht_dict['Reported Count'], cum_triangle_rng)\n",
    "cum_closed_count = Triangle.from_excel(file, 'Closed Count', 1, sht_dict['Closed Count'], cum_triangle_rng)\n",
    "\n",
    "inc_rpt_loss = Triangle.from_excel(file, 'Reported Loss', 1, sht_dict['Reported Loss'], inc_triangle_rng)\n",
    "inc_paid_loss = Triangle.from_excel(file, 'Paid Loss', 1, sht_dict['Paid Loss'], inc_triangle_rng)\n",
    "inc_paid_dcce = Triangle.from_excel(file, 'Paid DCCE', 1, sht_dict['Paid DCCE'], inc_triangle_rng)\n",
    "inc_rpt_count = Triangle.from_excel(file, 'Reported Count', 1, sht_dict['Reported Count'], inc_triangle_rng)\n",
    "inc_closed_count = Triangle.from_excel(file, 'Closed Count', 1, sht_dict['Closed Count'], inc_triangle_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 60)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_rpt_loss.triangle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cum_rpt_loss.triangle.columns.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1   2   3   4   5   6   7   8   9   ...  50  51  52  53  54  55  56  \\\n",
       "0   1   2   3   0   1   2   3   0   1   2  ...   3   0   1   2   3   0   1   \n",
       "\n",
       "   57  58  59  \n",
       "0   2   3   0  \n",
       "\n",
       "[1 rows x 60 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_qtr = pd.DataFrame(pd.Series([int((c % 12)/3) for c in cum_rpt_loss.triangle.columns]).values.reshape(1, cum_rpt_loss.triangle.columns.shape[0]))\n",
    "val_qtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m q1_val \u001b[39m=\u001b[39m {}\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m [cum_rpt_loss, cum_paid_loss, cum_paid_dcce, cum_rpt_count, cum_closed_count]:\n\u001b[1;32m----> 4\u001b[0m     q1_val[t\u001b[39m.\u001b[39mid] \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mtriangle\u001b[39m.\u001b[39;49mloc[:, val_qtr\u001b[39m.\u001b[39;49mloc[\u001b[39m0\u001b[39;49m, :]\u001b[39m.\u001b[39;49meq(\u001b[39m1\u001b[39;49m)]\n",
      "File \u001b[1;32mc:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\pandas\\core\\indexing.py:1067\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1065\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m   1066\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[1;32m-> 1067\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[0;32m   1068\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1069\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[0;32m   1070\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\pandas\\core\\indexing.py:1256\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m   1253\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[0;32m   1254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[1;32m-> 1256\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[1;32mc:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\pandas\\core\\indexing.py:924\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[1;34m(self, tup)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[0;32m    922\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m--> 924\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[0;32m    925\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[1;32mc:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\pandas\\core\\indexing.py:1292\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1290\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_slice_axis(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m   1291\u001b[0m \u001b[39melif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 1292\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getbool_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1293\u001b[0m \u001b[39melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m   1294\u001b[0m \n\u001b[0;32m   1295\u001b[0m     \u001b[39m# an iterable multi-selection\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[1;32mc:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\pandas\\core\\indexing.py:1091\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1087\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   1088\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_getbool_axis\u001b[39m(\u001b[39mself\u001b[39m, key, axis: \u001b[39mint\u001b[39m):\n\u001b[0;32m   1089\u001b[0m     \u001b[39m# caller is responsible for ensuring non-None axis\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m     labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1091\u001b[0m     key \u001b[39m=\u001b[39m check_bool_indexer(labels, key)\n\u001b[0;32m   1092\u001b[0m     inds \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1093\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_take_with_is_copy(inds, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\AndyW\\anaconda3\\envs\\rocky-env\\lib\\site-packages\\pandas\\core\\indexing.py:2552\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[1;34m(index, key)\u001b[0m\n\u001b[0;32m   2550\u001b[0m indexer \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_indexer_for(index)\n\u001b[0;32m   2551\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39min\u001b[39;00m indexer:\n\u001b[1;32m-> 2552\u001b[0m     \u001b[39mraise\u001b[39;00m IndexingError(\n\u001b[0;32m   2553\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnalignable boolean Series provided as \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2554\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mindexer (index of the boolean Series and of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2555\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mthe indexed object do not match).\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2556\u001b[0m     )\n\u001b[0;32m   2558\u001b[0m result \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m   2560\u001b[0m \u001b[39m# fall through for boolean\u001b[39;00m\n",
      "\u001b[1;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "# val_qtr = pd.Series([int((c % 12)/3) for c in cum_rpt_loss.triangle.columns])\n",
    "q1_val = {}\n",
    "for t in [cum_rpt_loss, cum_paid_loss, cum_paid_dcce, cum_rpt_count, cum_closed_count]:\n",
    "    q1_val[t.id] = t.triangle.loc[:, val_qtr.loc[0, :].eq(1)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your input data and labels are in Pandas DataFrames or Numpy arrays\n",
    "input_data = ...  # Load your input data here\n",
    "labels = ...  # Load your labels here\n",
    "\n",
    "# Reshape the input data to include a channel dimension (required for the Conv2d layer)\n",
    "# and convert it to a Numpy array, assuming the input_data is a Pandas DataFrame\n",
    "input_data = input_data.values.reshape(-1, 1, 2, 2)\n",
    "\n",
    "# If your input_data is already a Numpy array, use the following line instead:\n",
    "# input_data = input_data.reshape(-1, 1, 2, 2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. split into train/test sets and convert to pytorch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(input_data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. create DataLoader objects for train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch size is the number \n",
    "batch_size = 32\n",
    "\n",
    "# Use the TensorDataset and DataLoader classes to load the data in batches\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. instantiate the model, define loss function and optimizer\n",
    "\n",
    "$$\n",
    "\\text{binary cross entropy loss (BCE)} = -\\frac{1}{N}\\sum_{i=1}^N\\left[y_i\\log(p_i) + (1-y_i)\\log(1-p_i)\\right]\n",
    "$$\n",
    "Note that $p_i$ is the predicted probability of the positive class (i.e. the probability that the triangle is cumulative), and $y_i$ is the true label (either 0 or 1). Also consider logit function $f(x) = \\log\\left(\\frac{x}{1-x}\\right)$, which maps the probability $x$ to the log-odds $f(x)$. Thus BCE loss is equivalent to the following loss function:\n",
    "$$\n",
    "\\text{BCE} = -\\frac{1}{N}\\sum_{i=1}^N\\left[y_i\\log\\left(\\frac{p_i}{1-p_i}\\right) + (1-y_i)\\log\\left(\\frac{1-p_i}{p_i}\\right)\\right]\n",
    "$$  \n",
    "\n",
    "Comare this to logistic regression loss function:\n",
    "$$\n",
    "\\text{logistic regression loss} = -\\frac{1}{N}\\sum_{i=1}^N\\left[y_i\\log\\left(\\frac{p_i}{1-p_i}\\right) + (1-y_i)\\log\\left(\\frac{1-p_i}{p_i}\\right)\\right]\n",
    "$$\n",
    "where $p_i$ is the predicted probability of the positive class (i.e. the probability that the triangle is cumulative), and $y_i$ is the true label (either 0 or 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of classes you want to classify -- since I have 1 and 0, I have 2 classes\n",
    "num_classes = 2\n",
    "\n",
    "# Set the device to GPU if available, otherwise CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model\n",
    "model = SimpleCNN(num_classes).to(device)\n",
    "\n",
    "# Define the loss function. Since I have a binary classification problem,\n",
    "# use binary cross entropy loss, which is equivalent to logistic regression\n",
    "# loss, defined as:\n",
    "# loss = -1/n * sum(y * log(p) + (1 - y) * log(1 - p))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / (i + 1):.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rocky-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
