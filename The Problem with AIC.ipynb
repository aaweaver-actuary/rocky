{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective function minimized in ordinary least squares regression is:\n",
    "\n",
    "$$\n",
    "\\min_{\\beta} \\frac{1}{2n} \\sum_{i=1}^n (y_i - \\beta_0 - \\mathbf{x}_i^T \\beta)^2\n",
    "$$\n",
    "\n",
    "The objective function minimized in Elastic Net regularization is\n",
    "\n",
    "$$\n",
    "\\min_{\\beta} \\frac{1}{2n} \\sum_{i=1}^n (y_i - \\beta_0 - \\mathbf{x}_i^T \\beta)^2 + \\alpha \\lambda \\|\\beta\\|_1 + \\frac{\\alpha (1-\\lambda)}{2} \\|\\beta\\|_2^2\n",
    "$$\n",
    "\n",
    "- $\\alpha$ is the strength of regularization\n",
    "- $\\lambda$ controls the ratio of L1 and L2 regularization\n",
    "- $\\beta$ is the vector of coefficients\n",
    "\n",
    "Regularization like this introduces bias into the model (on purpose) in order to make the model more robust to overfitting.  The bias is controlled by the regularization strength $\\alpha$. This bias is used to help control the variance, especially in situations where there are many correlated features, or when overfitting is a concern. \n",
    "\n",
    "Because of this purposely-added bias term $\\left( \\alpha \\lambda \\|\\beta\\|_1 + \\frac{\\alpha (1-\\lambda)}{2} \\|\\beta\\|_2^2 \\right) $, the model will not fit the training data as well as it would without regularization.  However, the model will generalize better to new data, because it is less sensitive to the training data.  This is the bias-variance tradeoff in action.\n",
    "\n",
    "Additionally, the bias introduced implies that the parameter estimates fulfilling the objective function will not be the same as the parameter estimates from maximum likelihood estimation, and so likelihood-based methods like AIC and BIC are not appropriate for models fit with regularization.\n",
    "\n",
    "AIC and BIC are only useful when using maximum likelihood estimation to fit the model (because of the heavy reliance on (log)likelihood to define goodness-of-fit). Regularization introduces bias into the model, and so the parameter estimates from regularization will not be the same as the parameter estimates from maximum likelihood estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
